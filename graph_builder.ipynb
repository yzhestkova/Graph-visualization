{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code takes a network of technology clusters in table format and builds year-specific graphs from it with varying node size, coloring according to the degree and weight-specific edge width. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import re\n",
    "import numpy as np\n",
    "#import spacy\n",
    "import string\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading file with patents\n",
    "patents=pd.read_csv('patents.csv')\n",
    "patents=patents[['patent','appyear']]\n",
    "patents=patents.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading file with patent-article matches\n",
    "matches=pd.read_csv('complete_matches_full.csv')\n",
    "matches=pd.merge(matches, patents, how='inner', left_on='patent', right_on='patent')\n",
    "matches=matches.drop_duplicates()\n",
    "#Computing number of annual patents per article\n",
    "pat_per_art=matches[['article_title','patent','appyear']].groupby(['article_title','appyear']).agg(['count'])\n",
    "temp=matches[['patent','appyear']].groupby(['appyear']).agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_per_art=pat_per_art.reset_index()\n",
    "temp=temp.reset_index()\n",
    "pat_per_art.columns=['article_title','appyear','pat_per_year']\n",
    "temp.columns=['appyear','all_pat']\n",
    "pat_per_art=pd.merge(pat_per_art, temp, how='inner', left_on='appyear', right_on='appyear')\n",
    "pat_per_art['share']=pat_per_art['pat_per_year']/pat_per_art['all_pat'] #this will the size of the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a frame of all possible year-article combination to account for zero patenting in these clusters sometimes\n",
    "titles=pat_per_art[['article_title']]\n",
    "titles=titles.drop_duplicates()\n",
    "titles['key']=0\n",
    "years=list(range(1978,2015,1))\n",
    "years=pd.DataFrame(years)\n",
    "years.columns=['appyear']\n",
    "years['key']=0\n",
    "frame=pd.merge(years, titles, how='outer', left_on='key', right_on='key')\n",
    "frame=frame.drop(['key'], axis=1)\n",
    "pat_per_art=pd.merge(pat_per_art, frame, how='outer', left_on=['appyear','article_title'], right_on=['appyear','article_title'])\n",
    "pat_per_art=pat_per_art.sort_values(by=['article_title','appyear'])\n",
    "pat_per_art['pat_per_year']=np.where((pat_per_art['appyear']==1978) & (pat_per_art['pat_per_year'].isnull()), 0, pat_per_art['pat_per_year'])\n",
    "pat_per_art['share']=np.where(pat_per_art['appyear']==0, 0, pat_per_art['share'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading file with network in dataframe format\n",
    "link_work=pd.read_csv('link_all.csv')\n",
    "link_work['weight']=1/link_work['level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looping through different years and creating year-specific network\n",
    "\n",
    "for year in range(1976, 2013):\n",
    "    \n",
    "    working_pat=pat_per_art[pat_per_art['appyear']==year]\n",
    "    #Selecting only relevant parts of the network for this year\n",
    "    link_for_year=pd.merge(link_work, working_pat, how='inner', right_on='article_title', left_on='link_from')\n",
    "    link_for_year=link_for_year[['link_from','link_to','weight']]\n",
    "    link_for_year=pd.merge(link_for_year, working_pat, how='inner', right_on='article_title', left_on='link_to')\n",
    "    link_for_year=link_for_year[['link_from','link_to','weight']]\n",
    "    link_for_year=link_for_year.drop_duplicates()\n",
    "    \n",
    "    #Feeding network into the graph interpreter\n",
    "    G_year = nx.from_pandas_edgelist(link_for_year, source='link_from', target='link_to', edge_attr='weight', create_using=nx.Graph())\n",
    "    test_attr=pd.DataFrame(list(sorted(G_year.nodes)))\n",
    "    test_attr.columns=['article_title']\n",
    "    \n",
    "    #Adding nodes attributes - size\n",
    "    test_attr=pd.merge(test_attr, working_pat, how='inner', left_on='article_title', right_on='article_title') \n",
    "    test_attr=test_attr[['article_title','share']]\n",
    "    k=0\n",
    "    for i in sorted(G_year.nodes()):\n",
    "        G_year.nodes[i]['share'] = test_attr.loc[k,'share']\n",
    "        k=k+1\n",
    "    #Adding labels for the top-20 nodes by size\n",
    "    test_attr=test_attr.sort_values(by=['share'], ascending=False)\n",
    "    test_attr=test_attr.reset_index(drop=True)\n",
    "    label= [0]*20\n",
    "    for i in range(20):\n",
    "        label[i]=test_attr.iloc[i][0]\n",
    "        \n",
    "    plt.ioff()\n",
    "    plt.figure(figsize=(9,5), dpi=300)\n",
    "    plt.subplot()\n",
    "    #plt.subplots_adjust(left=5, right=5.02)\n",
    "\n",
    "    #Making color of the node vary with its degree\n",
    "    node_color = [G_year.degree(v) for v in G_year]\n",
    "    #Making size of the node vary with the size of a cluster\n",
    "    node_size = [12000*nx.get_node_attributes(G_year, 'share')[v] for v in G_year]\n",
    "    #Making width of the edges vary with the weight of the connection\n",
    "    edge_width = [0.5/G_year[u][v]['weight'] for u,v in G_year.edges()]\n",
    "\n",
    "    #Drawing pretty graphs and saving them to files\n",
    "    nx.draw_networkx(G_year, pos, font_size=7, labels={label[0]:str(label[0]),label[1]:str(label[1]),label[2]:str(label[2]),label[3]:str(label[3]),label[4]:str(label[4]),label[5]:str(label[5]),label[6]:str(label[6]),label[7]:str(label[7]),label[8]:str(label[8]),label[9]:str(label[9]), label[10]:str(label[10]),label[11]:str(label[11]),label[12]:str(label[12]),label[13]:str(label[13]),label[14]:str(label[14]),label[15]:str(label[15]),label[16]:str(label[16]),label[17]:str(label[17]),label[18]:str(label[18]),label[19]:str(label[19])}, font_color='Black', width=edge_width, node_color=node_color, node_size=node_size, alpha=0.7, edgecolors='peru', with_labels=True, edge_color='.8', cmap=plt.cm.Oranges)\n",
    "    plt.title(year, loc='left')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(year)+'.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
